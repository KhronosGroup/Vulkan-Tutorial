= Vulkan Integration

In this section, we'll integrate our PBR implementation with the rest of the Vulkan rendering pipeline. We'll update our renderer class to support advanced lighting techniques that can be used with glTF models and their PBR materials. The techniques we develop here will be applied in the Loading_Models chapter when we load and render glTF models.

To keep the flow concrete and avoid repeating earlier theory, use this quick roadmap:

1) Extend the renderer with PBR pipeline objects and a material push-constant block
2) Create the PBR pipeline (layout, shaders, blending, formats) alongside the main pipeline
3) Record draws: bind PBR pipeline, bind geometry, and push per-material constants per mesh
4) Clean up via RAII (no special teardown required)

[NOTE]
====
We wonâ€™t re-explain PBR theory or push-constant fundamentals here. See Lighting_Materials/03_push_constants.adoc for push constants and Lighting_Materials/01_introduction.adoc (and 05_pbr_rendering.adoc) for PBR concepts.
====

The PBR pass slots into the graphics pipeline as shown below:

image::../../../images/rendering_pipeline_flowchart.png[Rendering Pipeline Flowchart, width=600, alt=Rendering pipeline flowchart showing where the PBR pass fits]

== Updating the Renderer Class

First, let's update our renderer class to include the new members we need for our PBR implementation:

[source,cpp]
----
class Renderer {
public:
    // ... existing members ...

    // PBR pipeline
    vk::raii::PipelineLayout pbrPipelineLayout;
    vk::raii::Pipeline pbrPipeline;

    // Push constant block for PBR material properties
    struct PushConstantBlock {
        glm::vec4 baseColorFactor;
        float metallicFactor;
        float roughnessFactor;
        int baseColorTextureSet;
        int physicalDescriptorTextureSet;
        int normalTextureSet;
        int occlusionTextureSet;
        int emissiveTextureSet;
        float alphaMask;
        float alphaMaskCutoff;
    };

    // ... existing methods ...

    // New methods
    bool createPBRPipeline();
    void pushMaterialProperties(vk::CommandBuffer commandBuffer, const Model* model, uint32_t materialIndex);
};
----

We've added members for the PBR pipeline and a struct for PBR material properties. We've also added methods for creating the PBR pipeline and pushing material properties to the shader.

== Updating the Initialization

Next, we need to update the initialization process to create our PBR pipeline:

[source,cpp]
----
bool Renderer::Initialize(const std::string& appName, bool enableValidationLayers) {
    // ... existing initialization code ...

    // Create graphics pipeline
    if (!createGraphicsPipeline()) {
        return false;
    }

    // Create PBR pipeline
    if (!createPBRPipeline()) {
        std::cerr << "Failed to create PBR pipeline" << std::endl;
        return false;
    }

    // ... rest of initialization code ...

    initialized = true;
    return true;
}
----

== Updating the Cleanup

We also need to update the cleanup process to destroy our PBR pipeline:

[source,cpp]
----
void Renderer::Cleanup() {
    // ... existing cleanup code ...

    // With vk::raii, pipeline and pipeline layout objects are automatically destroyed
    // when they go out of scope, so we don't need explicit destruction calls

    // ... rest of cleanup code ...
}
----

== Updating the Rendering Process

Finally, we need to update the rendering process to use our PBR pipeline and push material properties:

[source,cpp]
----
void Renderer::recordCommandBuffer(vk::CommandBuffer commandBuffer, uint32_t imageIndex) {
    // ... existing command buffer recording code ...

    // Bind the PBR pipeline
    commandBuffer.bindPipeline(vk::PipelineBindPoint::eGraphics, *pbrPipeline);

    // For each model in the scene
    for (const auto& model : models) {
        // Bind vertex and index buffers
        vk::Buffer vertexBuffers[] = {model->vertexBuffer};
        vk::DeviceSize offsets[] = {0};
        commandBuffer.bindVertexBuffers(0, 1, vertexBuffers, offsets);
        commandBuffer.bindIndexBuffer(model->indexBuffer, 0, vk::IndexType::eUint32);

        // For each mesh in the model
        for (const auto& mesh : model->meshes) {
            // Push material properties
            pushMaterialProperties(commandBuffer, model, mesh.materialIndex);

            // Bind descriptor sets
            commandBuffer.bindDescriptorSets(
                vk::PipelineBindPoint::eGraphics,
                *pbrPipelineLayout,
                0,
                1,
                &descriptorSets[imageIndex],
                0,
                nullptr
            );

            // Draw
            commandBuffer.drawIndexed(mesh.indexCount, 1, mesh.firstIndex, 0, 0);
        }
    }

    // ... rest of command buffer recording code ...
}
----

== Creating the PBR Shader

Now that we've updated our renderer to support our PBR implementation, we need to create the PBR shader that implements the concepts we've discussed in this chapter. Rather than presenting this as a monolithic code dump, let's break down the shader creation into logical sections that explain both the technical implementation and the reasoning behind each component.

=== Section 1: Shader Structure and Data Interface

The first section establishes the communication interface between our CPU application and GPU shader, defining how data flows through the rendering pipeline.

[source,cpp]
----
// Combined vertex and fragment shader for PBR rendering

// Input from vertex buffer - Data sent per vertex from CPU
struct VSInput {
    float3 Position : POSITION;     // 3D position in model space
    float3 Normal : NORMAL;         // Surface normal for lighting calculations
    float2 UV : TEXCOORD0;          // Texture coordinates for material sampling
    float4 Tangent : TANGENT;       // Tangent vector for normal mapping (w component = handedness)
};

// Output from vertex shader / Input to fragment shader - Interpolated data
struct VSOutput {
    float4 Position : SV_POSITION; // Required clip space position for rasterization
    float3 WorldPos : POSITION;    // World space position for lighting calculations
    float3 Normal : NORMAL;        // World space normal (interpolated)
    float2 UV : TEXCOORD0;         // Texture coordinates (interpolated)
    float4 Tangent : TANGENT;      // World space tangent (interpolated)
};

// Uniform buffer - Global data shared across all vertices/fragments
struct UniformBufferObject {
    float4x4 model;                     // Model-to-world transformation matrix
    float4x4 view;                      // World-to-camera transformation matrix
    float4x4 proj;                      // Camera-to-clip space projection matrix
    float4 lightPositions[4];           // Light positions in world space
    float4 lightColors[4];              // Light intensities and colors
    float4 camPos;                      // Camera position for view-dependent effects
    float exposure;                     // HDR exposure control
    float gamma;                        // Gamma correction value (typically 2.2)
    float prefilteredCubeMipLevels;     // IBL prefiltered environment map mip levels
    float scaleIBLAmbient;              // IBL ambient contribution scale
};

// Push constants - Fast, small data updated frequently per material/object
struct PushConstants {
    float4 baseColorFactor;             // Base color tint/multiplier
    float metallicFactor;               // Metallic property multiplier
    float roughnessFactor;              // Surface roughness multiplier
    int baseColorTextureSet;            // Texture binding index for base color (-1 = none)
    int physicalDescriptorTextureSet;   // Texture binding for metallic/roughness
    int normalTextureSet;               // Texture binding for normal maps
    int occlusionTextureSet;            // Texture binding for ambient occlusion
    int emissiveTextureSet;             // Texture binding for emissive maps
    float alphaMask;                    // Alpha masking enable flag
    float alphaMaskCutoff;              // Alpha cutoff threshold
};

// Mathematical constants
static const float PI = 3.14159265359;

// Resource bindings - Connect CPU resources to GPU shader registers
[[vk::binding(0, 0)]] ConstantBuffer<UniformBufferObject> ubo;
[[vk::binding(1, 0)]] Texture2D baseColorMap;
[[vk::binding(1, 0)]] SamplerState baseColorSampler;
[[vk::binding(2, 0)]] Texture2D metallicRoughnessMap;
[[vk::binding(2, 0)]] SamplerState metallicRoughnessSampler;
[[vk::binding(3, 0)]] Texture2D normalMap;
[[vk::binding(3, 0)]] SamplerState normalSampler;
[[vk::binding(4, 0)]] Texture2D occlusionMap;
[[vk::binding(4, 0)]] SamplerState occlusionSampler;
[[vk::binding(5, 0)]] Texture2D emissiveMap;
[[vk::binding(5, 0)]] SamplerState emissiveSampler;

[[vk::push_constant]] PushConstants material;
----

This interface design reflects modern GPU architecture principles where different types of data flow through different pathways based on their update frequency and size. Uniform buffers efficiently handle large, infrequently changing data like transformation matrices, while push constants provide ultra-fast updates for small, frequently changing material properties.

=== Section 2: PBR Mathematical Foundation

The second section implements the core mathematical functions that form the foundation of physically-based rendering, translating complex light-surface interactions into computationally efficient approximations.

[source,cpp]
----
// Normal Distribution Function (D) - GGX/Trowbridge-Reitz Distribution
// Describes the statistical distribution of microfacet orientations
float DistributionGGX(float NdotH, float roughness) {
    float a = roughness * roughness;        // Remapping for more perceptual linearity
    float a2 = a * a;
    float NdotH2 = NdotH * NdotH;

    float nom = a2;                         // Numerator: concentration factor
    float denom = (NdotH2 * (a2 - 1.0) + 1.0);
    denom = PI * denom * denom;             // Normalization factor

    return nom / denom;                     // Normalized distribution
}

// Geometry Function (G) - Smith's method with Schlick-GGX approximation
// Models self-shadowing and masking between microfacets
float GeometrySmith(float NdotV, float NdotL, float roughness) {
    float r = roughness + 1.0;
    float k = (r * r) / 8.0;               // Direct lighting remapping

    // Geometry obstruction from view direction (masking)
    float ggx1 = NdotV / (NdotV * (1.0 - k) + k);
    // Geometry obstruction from light direction (shadowing)
    float ggx2 = NdotL / (NdotL * (1.0 - k) + k);

    return ggx1 * ggx2;                     // Combined masking-shadowing
}

// Fresnel Reflectance (F) - Schlick's approximation
// Models how reflectance changes with viewing angle
float3 FresnelSchlick(float cosTheta, float3 F0) {
    return F0 + (1.0 - F0) * pow(1.0 - cosTheta, 5.0);
}
----

These mathematical functions represent decades of computer graphics research distilled into efficient real-time approximations. The GGX distribution provides more realistic highlight falloff compared to older models, while the Smith geometry function ensures energy conservation at grazing angles. The Fresnel approximation captures the essential angle-dependent reflection behavior that makes materials look convincing under different viewing conditions.

=== Section 3: Vertex and Fragment Shader Implementation

The final section contains the actual shader entry points that execute for each vertex and pixel, implementing the complete PBR pipeline from geometry transformation through final color output.

[source,cpp]
----
// Vertex shader entry point - Executes once per vertex
[[shader("vertex")]]
VSOutput VSMain(VSInput input)
{
    VSOutput output;

    // Transform vertex position through the rendering pipeline
    // Model -> World -> Camera -> Clip space transformation chain
    float4 worldPos = mul(ubo.model, float4(input.Position, 1.0));
    output.Position = mul(ubo.proj, mul(ubo.view, worldPos));

    // Pass world position for fragment lighting calculations
    // Fragment shader needs world space position to calculate light vectors
    output.WorldPos = worldPos.xyz;

    // Transform normal from model space to world space
    // Use only rotation/scale part of model matrix (upper-left 3x3)
    // Normalize to ensure unit length after transformation
    output.Normal = normalize(mul((float3x3)ubo.model, input.Normal));

    // Pass through texture coordinates unchanged
    // UV coordinates are typically in [0,1] range and don't need transformation
    output.UV = input.UV;

    // Pass tangent vector for normal mapping
    // Will be used in fragment shader to construct tangent-space basis
    output.Tangent = input.Tangent;

    return output;
}

// Fragment shader entry point - Executes once per pixel
[[shader("fragment")]]
float4 PSMain(VSOutput input) : SV_TARGET
{
    // === MATERIAL PROPERTY SAMPLING ===
    // Sample base color texture and apply material color factor
    float4 baseColor = baseColorMap.Sample(baseColorSampler, input.UV) * material.baseColorFactor;

    // Sample metallic-roughness texture (metallic=B channel, roughness=G channel)
    // glTF standard: metallic stored in blue, roughness in green
    float2 metallicRoughness = metallicRoughnessMap.Sample(metallicRoughnessSampler, input.UV).bg;
    float metallic = metallicRoughness.x * material.metallicFactor;
    float roughness = metallicRoughness.y * material.roughnessFactor;

    // Sample ambient occlusion (typically stored in red channel)
    float ao = occlusionMap.Sample(occlusionSampler, input.UV).r;

    // Sample emissive texture for self-illuminating materials
    float3 emissive = emissiveMap.Sample(emissiveSampler, input.UV).rgb;

    // === NORMAL CALCULATION ===
    // Start with interpolated surface normal
    float3 N = normalize(input.Normal);

    // Apply normal mapping if texture is available
    if (material.normalTextureSet >= 0) {
        // Sample normal map and convert from [0,1] to [-1,1] range
        float3 tangentNormal = normalMap.Sample(normalSampler, input.UV).xyz * 2.0 - 1.0;

        // Construct tangent-space to world-space transformation matrix (TBN)
        float3 T = normalize(input.Tangent.xyz);              // Tangent
        float3 B = normalize(cross(N, T)) * input.Tangent.w;  // Bitangent (w = handedness)
        float3x3 TBN = float3x3(T, B, N);                     // Tangent-Bitangent-Normal matrix

        // Transform normal from tangent space to world space
        N = normalize(mul(tangentNormal, TBN));
    }

    // === LIGHTING SETUP ===
    // Calculate view direction (camera to fragment)
    float3 V = normalize(ubo.camPos.xyz - input.WorldPos);

    // Calculate reflection vector for environment mapping
    float3 R = reflect(-V, N);

    // === PBR MATERIAL SETUP ===
    // Calculate F0 (reflectance at normal incidence)
    // Non-metals: low reflectance (~0.04), Metals: colored reflectance from base color
    float3 F0 = float3(0.04, 0.04, 0.04);  // Dielectric default
    F0 = lerp(F0, baseColor.rgb, metallic); // Lerp to metallic behavior

    // Initialize outgoing radiance accumulator
    float3 Lo = float3(0.0, 0.0, 0.0);

    // === DIRECT LIGHTING LOOP ===
    // Calculate contribution from each light source
    for (int i = 0; i < 4; i++) {
        float3 lightPos = ubo.lightPositions[i].xyz;
        float3 lightColor = ubo.lightColors[i].rgb;

        // Calculate light direction and attenuation
        float3 L = normalize(lightPos - input.WorldPos);      // Light direction
        float distance = length(lightPos - input.WorldPos);   // Distance for falloff
        float attenuation = 1.0 / (distance * distance);     // Inverse square falloff
        float3 radiance = lightColor * attenuation;           // Attenuated light color

        // Calculate half vector (between view and light directions)
        float3 H = normalize(V + L);

        // === BRDF EVALUATION ===
        // Calculate all necessary dot products for BRDF terms
        float NdotL = max(dot(N, L), 0.0);  // Lambertian falloff
        float NdotV = max(dot(N, V), 0.0);  // View angle
        float NdotH = max(dot(N, H), 0.0);  // Half vector for specular
        float HdotV = max(dot(H, V), 0.0);  // For Fresnel calculation

        // Evaluate Cook-Torrance BRDF components
        float D = DistributionGGX(NdotH, roughness);    // Normal distribution
        float G = GeometrySmith(NdotV, NdotL, roughness); // Geometry function
        float3 F = FresnelSchlick(HdotV, F0);           // Fresnel reflectance

        // Calculate specular BRDF
        float3 numerator = D * G * F;
        float denominator = 4.0 * NdotV * NdotL + 0.0001; // Prevent division by zero
        float3 specular = numerator / denominator;

        // === ENERGY CONSERVATION ===
        // Fresnel term represents specular reflection ratio
        float3 kS = F;                          // Specular contribution
        float3 kD = float3(1.0, 1.0, 1.0) - kS; // Diffuse contribution (energy conservation)
        kD *= 1.0 - metallic;                   // Metals have no diffuse reflection

        // === RADIANCE ACCUMULATION ===
        // Combine diffuse (Lambertian) and specular (Cook-Torrance) terms
        // Multiply by incident radiance and cosine foreshortening
        Lo += (kD * baseColor.rgb / PI + specular) * radiance * NdotL;
    }

    // === AMBIENT AND EMISSIVE ===
    // Add simple ambient lighting (should be replaced with IBL in production)
    float3 ambient = float3(0.03, 0.03, 0.03) * baseColor.rgb * ao;

    // Combine all lighting contributions
    float3 color = ambient + Lo + emissive;

    // === HDR TONE MAPPING AND GAMMA CORRECTION ===
    // Apply Reinhard tone mapping to compress HDR values to [0,1] range
    color = color / (color + float3(1.0, 1.0, 1.0));

    // Apply gamma correction for sRGB display (inverse gamma)
    color = pow(color, float3(1.0 / ubo.gamma, 1.0 / ubo.gamma, 1.0 / ubo.gamma));

    // Output final color with original alpha
    return float4(color, baseColor.a);
}
----

== Compiling the Shader

After creating the shader file, we need to compile it using slangc. This is typically done as part of the build process, but we can also do it manually:

[source,bash]
----
slangc shaders/pbr.slang -target spirv -profile spirv_1_4 -emit-spirv-directly -o shaders/pbr.spv
----

== Testing the Implementation with glTF Models

To test our implementation, we can use glTF models, which already have PBR materials defined that are compatible with our implementation. In the Loading_Models chapter, we'll learn how to load these models, but for now, let's assume we have a way to load them.

Here's an example of how to set up a test scene with glTF models:

[source,cpp]
----
void Renderer::renderTestScene() {
    // Set up camera
    glm::vec3 cameraPos = glm::vec3(0.0f, 0.0f, 3.0f);
    glm::vec3 cameraTarget = glm::vec3(0.0f, 0.0f, 0.0f);
    glm::vec3 cameraUp = glm::vec3(0.0f, 1.0f, 0.0f);

    // Set up lights
    // Light 1: White light from above
    glm::vec4 lightPos1 = glm::vec4(0.0f, 5.0f, 5.0f, 1.0f);
    glm::vec4 lightColor1 = glm::vec4(300.0f, 300.0f, 300.0f, 1.0f);

    // Light 2: Blue light from the left
    glm::vec4 lightPos2 = glm::vec4(-5.0f, 0.0f, 0.0f, 1.0f);
    glm::vec4 lightColor2 = glm::vec4(0.0f, 0.0f, 300.0f, 1.0f);

    // Load glTF models
    Model* damagedHelmet = modelLoader.loadModel("models/DamagedHelmet/DamagedHelmet.gltf");
    Model* flightHelmet = modelLoader.loadModel("models/FlightHelmet/FlightHelmet.gltf");

    // The models already have PBR materials defined in the glTF file
    // We can render them directly with our PBR pipeline

    // Render the models with different transformations
    renderModel(damagedHelmet, glm::vec3(-1.0f, 0.0f, 0.0f), glm::vec3(0.5f));
    renderModel(flightHelmet, glm::vec3(1.0f, 0.0f, 0.0f), glm::vec3(0.5f));

    // We can also experiment with modifying the material properties
    // For example, to make the damaged helmet more metallic:
    if (damagedHelmet->materials.size() > 0) {
        // Store the original value to restore later
        float originalMetallic = damagedHelmet->materials[0].metallicFactor;

        // Modify the material
        damagedHelmet->materials[0].metallicFactor = 1.0f;

        // Render with modified material
        renderModel(damagedHelmet, glm::vec3(-2.0f, 0.0f, 0.0f), glm::vec3(0.5f));

        // Restore original value
        damagedHelmet->materials[0].metallicFactor = originalMetallic;
    }
}
----

== Conclusion

In this section, we've integrated our PBR implementation with the rest of the Vulkan rendering pipeline. We've updated our renderer class to support advanced lighting techniques that can be used with glTF models and their PBR materials. We've created a PBR shader based on the concepts we've learned and shown how to test the implementation with glTF models.

This approach provides a solid foundation for rendering physically accurate materials, which we'll apply in the Loading_Models chapter when we load and render glTF models. It also gives us the flexibility to modify and extend the material properties as needed for our specific rendering requirements.

In the next section, we'll wrap up this chapter with a conclusion and discuss potential improvements and extensions to our lighting system.

link:04_lighting_implementation.adoc[Previous: Lighting Implementation] | link:06_conclusion.adoc[Next: Conclusion]
