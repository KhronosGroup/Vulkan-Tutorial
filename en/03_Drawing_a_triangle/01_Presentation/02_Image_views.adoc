:pp: {plus}{plus}

= Image views

In Vulkan, accessing and manipulating resources isn't done directly but rather
through *views* - these describe how to look at (or *view*) a subset of the
underlying data in a desired way. For instance, `VkBuffer` refers to a buffer
object which represents a linear array of data. To use a `VkBuffer` you have to
create a `VkBufferView` object which describes, among other things, the
accessible contiguous range of the underlying data (this is done by providing
an `offset` and a `range`).

Similarly, to use any `VkImage`, including those in the swap chain, in the
render pipeline we have to create a `VkImageView` object. The `VkImageView`
describes how to interpret the underlying image and which part of it to access,
for example, if it should be treated as a 2D texture depth texture without any
mipmapping levels.

In this chapter we'll write a `createImageViews` function that creates a basic
image view for every image in the swap chain so that we can use them as color
targets later on.

First, add a class member to store the image views in:

[,c++]
----
std::vector<vk::raii::ImageView> swapChainImageViews;
----

Create the `createImageViews` function and call it right after swap chain
creation:

[,c++]
----
void initVulkan() {
    createInstance();
    setupDebugMessenger();
    createSurface();
    pickPhysicalDevice();
    createLogicalDevice();
    createSwapChain();
    createImageViews();
}

void createImageViews() {

}
----

The parameters for image view creation are specified in a
`VkImageViewCreateInfo` structure. The first field is `flags` which is not
needed in our case.

Next is the `image` field which will be set to each `VkImage` from the swap
chain in the upcoming loop over the swap chain images.

Next, in the `viewType` field, we specify that we're rendering to a 2D screen.
If we wanted to render to a 3D screen or cube map, those are also options as is
a 1D screen.  As you can probably guess, we'd want a 2D render target in most
cases when we're rendering to a screen.

Next, in the `format` field, we specify the image format; this is how the
colorspace components are configured so you get the right color format in your
renders. In the case of swap chain image views, we want to use the same format
as the underlying swap chain `VkImage` objects.

The last field is the `subresourceRange` which describes what the purpose of
the image is and which part of it should be accessed. Our images will be used as
color targets without any mipmapping levels or multiple layers.

The `createImageViews` function should now look something like this:

[,c++]
----
void createImageViews() {
    swapChainImageViews.clear();

    vk::ImageViewCreateInfo imageViewCreateInfo{
        /* .image = will be overwritten in the subsequent loop */
        .viewType = vk::ImageViewType::e2D,
        .format = swapChainImageFormat,
        .subresourceRange = {.aspectMask = vk::ImageAspectFlagBits::eColor,
                             .baseMipLevel = 0,
                             .levelCount = 1,
                             .baseArrayLayer = 0,
                             .layerCount = 1},
    };
}
----

The `components` field (which is kept to default here) allows you to swizzle
the color channels around. For example, you can map all the channels to the red
channel for a monochrome texture. You can also map constant values of `0` and
`1` to a channel. The concept of swizzling will become much clearer once we get
to the Shader Modules chapter. In our case, we'll stick to the default mapping
by accepting the constructed defaults, but here's how to explicitly do it:

[,c++]
----
imageViewCreateInfo.components = {
    .r = vk::ComponentSwizzle::eIdentity,
    .g = vk::ComponentSwizzle::eIdentity,
    .b = vk::ComponentSwizzle::eIdentity,
    .a = vk::ComponentSwizzle::eIdentity,
};
----

If you were working on a stereographic 3D application, then you would create a
swap chain with multiple layers. You could then create multiple image views for
each image representing the views for the left and right eyes by accessing
different layers.

The maximum number of multiple image views you should expect graphics cards
to handle is 16. This configuration covers most standard use cases, VR/AR
headsets typically require no more than four simultaneous views. However,
lightfield displays and CAVE displays might require a different solution as
their view requirements can number in the thousands for simultaneous views.
Those exotic requirements for rendering are beyond the scope of this
tutorial, but even those use cases can be rendered to with these same
structures and techniques we describe here.

Next, set up the loop that iterates over all the swap chain images and add
them to our structure:

[,c++]
----
for (auto image : swapChainImages) {
    imageViewCreateInfo.image = image;
}
----

Creating the image view is now a matter of calling `vkCreateImageView`:

[,c++]
----
for (auto image : swapChainImages) {
    imageViewCreateInfo.image = image;
    swapChainImageViews.emplace_back( device, imageViewCreateInfo );
}
----

An image view is sufficient to start using an image as a texture, but it's not
quite ready to be used as a render target just yet. That requires one more step,
known as a *framebuffer*.
In the xref:/03_Drawing_a_triangle/02_Graphics_pipeline_basics/00_Introduction.adoc[next chapters,] we'll have to set up the graphics pipeline.

link:/attachments/07_image_views.cpp[C{pp} code]
